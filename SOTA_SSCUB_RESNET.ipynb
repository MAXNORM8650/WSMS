{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577fc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e5156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe4d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torchsummary import summary\n",
    "import random\n",
    "from utils.read_dataset import read_dataset\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5850e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import num_classes, model_name, model_path, lr_milestones, lr_decay_rate, input_size, \\\n",
    "    root, end_epoch, save_interval, init_lr, batch_size, CUDA_VISIBLE_DEVICES, weight_decay, \\\n",
    "    proposalN, set, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb24d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d659caa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9acb944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0.dev20221118+cu116\n"
     ]
    }
   ],
   "source": [
    "print(torch. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397fd5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25653b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4611bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop=r\"C:\\Users\\Admin\\Dropbox\\PC\\Documents\\FGVC_MSFM\\MMAL-Net\\datasets\\multiclass_path\\train_positive.txt\"\n",
    "# nop=r\"C:\\Users\\Admin\\Dropbox\\PC\\Documents\\FGVC_MSFM\\MMAL-Net\\datasets\\multiclass_path\\train_negative.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa218e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf=pd.read_table(nop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489c0ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf=pdf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c47c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf.to_csv(nop, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d317368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1f012ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
    "           'wide_resnet50_2', 'wide_resnet101_2']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
    "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
    "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
    "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, return_cam=True, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "#         self.SSPCAB_Block = SSPCAB(2048)\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.num_classes=num_classes\n",
    "        self.base_width = width_per_group\n",
    "        self.return_cam=return_cam\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=2048, out_channels=2048, kernel_size=4, stride=1,bias=False)\n",
    "        # self.conv3 = nn.Conv2d(in_channels=2048, out_channels=201, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512 * block.expansion, self.num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x=ViT('B_16')(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        conv5_b = self.layer4[:2](x)\n",
    "        x = self.layer4[2](conv5_b)\n",
    "\n",
    "        fm1 = x\n",
    "#         fm2 = self.SSPCAB_Block(fm1)\n",
    "#         x = self.avgpool(fm2)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.dropout(x)\n",
    "       \n",
    "#         embeeding = x\n",
    "#         logs=self.fc(embeeding)\n",
    "        \n",
    "        return fm1\n",
    "\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, pth_path, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = torch.load(pth_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, pth_path,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def resnet34(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"ResNet-34 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, pth_path,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def resnet50(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3],pretrained, pth_path,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def resnet101(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"ResNet-101 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, pth_path,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def resnet152(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"ResNet-152 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, pth_path,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def resnext50_32x4d(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"ResNeXt-50 32x4d model from\n",
    "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 4\n",
    "    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n",
    "                   pretrained, pth_path, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def resnext101_32x8d(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"ResNeXt-101 32x8d model from\n",
    "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 8\n",
    "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n",
    "                   pretrained, pth_path, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def wide_resnet50_2(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"Wide ResNet-50-2 model from\n",
    "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
    "\n",
    "    The model is the same as ResNet except for the bottleneck number of channels\n",
    "    which is twice larger in every block. The number of channels in outer 1x1\n",
    "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
    "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs['width_per_group'] = 64 * 2\n",
    "    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3],\n",
    "                   pretrained, pth_path, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def wide_resnet101_2(pth_path, pretrained=False, **kwargs):\n",
    "    r\"\"\"Wide ResNet-101-2 model from\n",
    "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
    "\n",
    "    The model is the same as ResNet except for the bottleneck number of channels\n",
    "    which is twice larger in every block. The number of channels in outer 1x1\n",
    "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
    "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs['width_per_group'] = 64 * 2\n",
    "    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],\n",
    "                   pretrained, pth_path, **kwargs)\n",
    "# Squeeze and Excitation block\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, num_channels, reduction_ratio=4):\n",
    "        '''\n",
    "            num_channels: The number of input channels\n",
    "            reduction_ratio: The reduction ratio 'r' from the paper\n",
    "        '''\n",
    "        super(SELayer, self).__init__()\n",
    "        num_channels_reduced = num_channels // reduction_ratio\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        self.fc1 = nn.Linear(num_channels, num_channels_reduced, bias=True)\n",
    "        self.fc2 = nn.Linear(num_channels_reduced, num_channels, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        batch_size, num_channels, H, W = input_tensor.size()\n",
    "\n",
    "        squeeze_tensor = input_tensor.view(batch_size, num_channels, -1).mean(dim=2)\n",
    "#         print(squeeze_tensor.shape)\n",
    "        # channel excitation\n",
    "        fc_out_1 = self.relu(self.fc1(squeeze_tensor))\n",
    "#         print(fc_out_1.shape)\n",
    "        fc_out_2 = self.sigmoid(self.fc2(fc_out_1))\n",
    "#         print(fc_out_2.shape)\n",
    "        a, b = squeeze_tensor.size()\n",
    "#         print(a,b)\n",
    "#         fc_out_2 = torch.reshape(fc_out_2, a, b, 1, 1)\n",
    "        output_tensor = torch.mul(input_tensor, fc_out_2.view(a, b, 1, 1))\n",
    "        return output_tensor\n",
    "\n",
    "\n",
    "# SSPCAB implementation\n",
    "class SSPCAB(nn.Module):\n",
    "    def __init__(self, channels, kernel_dim=1, dilation=1, reduction_ratio=4):\n",
    "        '''\n",
    "            channels: The number of filter at the output (usually the same with the number of filter from the input)\n",
    "            kernel_dim: The dimension of the sub-kernels ' k' ' from the paper\n",
    "            dilation: The dilation dimension 'd' from the paper\n",
    "            reduction_ratio: The reduction ratio for the SE block ('r' from the paper)\n",
    "        '''\n",
    "        super(SSPCAB, self).__init__()\n",
    "        self.pad = kernel_dim + dilation\n",
    "        self.border_input = kernel_dim + 2*dilation + 1\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.se = SELayer(channels, reduction_ratio=reduction_ratio)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=channels,\n",
    "                               out_channels=channels,\n",
    "                               kernel_size=kernel_dim)\n",
    "        self.conv2 = nn.Conv2d(in_channels=channels,\n",
    "                               out_channels=channels,\n",
    "                               kernel_size=kernel_dim)\n",
    "        self.conv3 = nn.Conv2d(in_channels=channels,\n",
    "                               out_channels=channels,\n",
    "                               kernel_size=kernel_dim)\n",
    "        self.conv4 = nn.Conv2d(in_channels=channels,\n",
    "                               out_channels=channels,\n",
    "                               kernel_size=kernel_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = F.pad(x, (self.pad, self.pad, self.pad, self.pad), \"constant\", 0)\n",
    "\n",
    "#         x1 = self.conv1(x[:, :, :-self.border_input, :-self.border_input])\n",
    "#         x2 = self.conv2(x[:, :, self.border_input:, :-self.border_input])\n",
    "#         x3 = self.conv3(x[:, :, :-self.border_input, self.border_input:])\n",
    "#         x4 = self.conv4(x[:, :, self.border_input:, self.border_input:])\n",
    "#         x = self.relu(x1 + x2 + x3 + x4)\n",
    "\n",
    "        x = self.se(x)\n",
    "        return x\n",
    "\n",
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.modelA(x)\n",
    "        x = self.modelB(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15364611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import measure\n",
    "x_test=torch.rand(1, 3, 448, 448)\n",
    "pretrain_path_B='./models/pretrained/resnet50-19c8e357.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "560ea594",
   "metadata": {},
   "outputs": [],
   "source": [
    "fms=torch.rand(1, 2, 14, 14)\n",
    "fm1=torch.rand(1, 2048, 14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01fdb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod=resnet50(pretrain_path_B, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1d87168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test=mod(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e5de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_1=mod(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5bce889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sigmoid(y_test_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "800d42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4db30fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y=A[0][0][:, 0], A[0][0][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe42d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce158f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a4ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e4315c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import measure\n",
    "def CFM2(fms):\n",
    "    A = torch.sum(fms, dim=1, keepdim=True)\n",
    "    a = torch.mean(A, dim=[2, 3], keepdim=True)\n",
    "    M = (A > a).float()\n",
    "\n",
    "    coordinates = []\n",
    "    for i, m in enumerate(M):\n",
    "        mask_np = m.cpu().numpy().reshape(14, 14)\n",
    "        component_labels = measure.label(mask_np)\n",
    "\n",
    "        properties = measure.regionprops(component_labels)\n",
    "        areas = []\n",
    "        for prop in properties:\n",
    "            areas.append(prop.area)\n",
    "        \n",
    "        max_idx = areas.index(max(areas))\n",
    "\n",
    "\n",
    "        intersection = ((component_labels==(max_idx+1)).astype(int))==1\n",
    "        \n",
    "        prop = measure.regionprops(intersection.astype(int))\n",
    "          \n",
    "        if len(prop) == 0:\n",
    "            bbox = [0, 0, 14, 14]\n",
    "            print('there is one img no intersection')\n",
    "        else:\n",
    "            \n",
    "            bbox = prop[0].bbox\n",
    "            print(bbox)\n",
    "#         print(\"B box is\",bbox)\n",
    "        x_lefttop = bbox[0] * 32 - 1\n",
    "        y_lefttop = bbox[1] * 32 - 1\n",
    "        x_rightlow = bbox[2] * 32 - 1\n",
    "        y_rightlow = bbox[3] * 32 - 1\n",
    "        # for image\n",
    "        if x_lefttop < 0:\n",
    "            x_lefttop = 0\n",
    "        if y_lefttop < 0:\n",
    "            y_lefttop = 0\n",
    "        coordinate = [x_lefttop, y_lefttop, x_rightlow, y_rightlow]\n",
    "        coordinates.append(coordinate)\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3906f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import measure\n",
    "def AOLM(fms, fm1):\n",
    "    A = torch.sum(fms, dim=1, keepdim=True)\n",
    "    a = torch.mean(A, dim=[2, 3], keepdim=True)\n",
    "    M = (A > a).float()\n",
    "\n",
    "    A1 = torch.sum(fm1, dim=1, keepdim=True)\n",
    "    a1 = torch.mean(A1, dim=[2, 3], keepdim=True)\n",
    "    M1 = (A1 > a1).float()\n",
    "\n",
    "\n",
    "    coordinates = []\n",
    "    for i, m in enumerate(M):\n",
    "        mask_np = m.cpu().numpy().reshape(14, 14)\n",
    "        component_labels = measure.label(mask_np, connectivity=2)\n",
    "\n",
    "        properties = measure.regionprops(component_labels)\n",
    "        areas = []\n",
    "        for prop in properties:\n",
    "            areas.append(prop.area)\n",
    "#         print(areas)\n",
    "        max_idx = areas.index(max(areas))\n",
    "\n",
    "\n",
    "        intersection = ((component_labels==(max_idx+1)).astype(int) + (M1[i][0].cpu().numpy()==1).astype(int)) ==2\n",
    "        prop = measure.regionprops(intersection.astype(int))\n",
    "        if len(prop) == 0:\n",
    "            bbox = [0, 0, 14, 14]\n",
    "#             print('there is one img no intersection')\n",
    "        else:\n",
    "            bbox = prop[0].bbox\n",
    "#             print(\"B box is\",bbox)\n",
    "        x_lefttop = bbox[0] * 32 - 1\n",
    "        y_lefttop = bbox[1] * 32 - 1\n",
    "        x_rightlow = bbox[2] * 32 - 1\n",
    "        y_rightlow = bbox[3] * 32 - 1\n",
    "        # for image\n",
    "        if x_lefttop < 0:\n",
    "            x_lefttop = 0\n",
    "        if y_lefttop < 0:\n",
    "            y_lefttop = 0\n",
    "        coordinate = [x_lefttop, y_lefttop, x_rightlow, y_rightlow]\n",
    "        coordinates.append(coordinate)\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11ef31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# segmentation function\n",
    "##################################\n",
    "def batch_segmentation(images, attention_map, mode='crop', theta=0.5, padding_ratio=0.1):\n",
    "    batches, _, imgH, imgW = images.size()\n",
    "\n",
    "    if mode == 'crop':\n",
    "        crop_images = []\n",
    "        for batch_index in range(batches):\n",
    "            atten_map = attention_map[batch_index:batch_index + 1]\n",
    "            if isinstance(theta, tuple):\n",
    "                theta_c = random.uniform(*theta) * atten_map.max()\n",
    "            else:\n",
    "                theta_c = theta * atten_map.max()\n",
    "\n",
    "            crop_mask = F.upsample_bilinear(atten_map, size=(imgH, imgW)) >= theta_c\n",
    "            nonzero_indices = torch.nonzero(crop_mask[0, 0, ...])\n",
    "            height_min = max(int(nonzero_indices[:, 0].min().item() - padding_ratio * imgH), 0)\n",
    "            height_max = min(int(nonzero_indices[:, 0].max().item() + padding_ratio * imgH), imgH)\n",
    "            width_min = max(int(nonzero_indices[:, 1].min().item() - padding_ratio * imgW), 0)\n",
    "            width_max = min(int(nonzero_indices[:, 1].max().item() + padding_ratio * imgW), imgW)\n",
    "\n",
    "            crop_images.append(\n",
    "                F.upsample_bilinear(images[batch_index:batch_index + 1, :, height_min:height_max, width_min:width_max],\n",
    "                                    size=(imgH, imgW)))\n",
    "        crop_images = torch.cat(crop_images, dim=0)\n",
    "        return crop_images\n",
    "\n",
    "    elif mode == 'drop':\n",
    "        drop_masks = []\n",
    "        for batch_index in range(batches):\n",
    "            atten_map = attention_map[batch_index:batch_index + 1]\n",
    "            if isinstance(theta, tuple):\n",
    "                theta_d = random.uniform(*theta) * atten_map.max()\n",
    "            else:\n",
    "                theta_d = theta * atten_map.max()\n",
    "            msk=F.upsample_bilinear(atten_map, size=(imgH, imgW)) < theta_d\n",
    "            q =msk.float()\n",
    "            tense_tensor = torch.tensor(q, device='cuda')\n",
    "            label=torch.where(tense_tensor==0.0, torch.tensor(2.0, device = 'cuda'), tense_tensor)\n",
    "#             drop_masks.append(label)\n",
    "            drop_masks.append(label2rgb(label, images[batch_index], kind = 'overlay'))\n",
    "        drop_masks = torch.cat(drop_masks, dim=0).float()\n",
    "#         label2rgb(astronaut_segments, image, kind = 'overlay')\n",
    "#         drop_images = images * drop_masks.float()\n",
    "        return drop_masks\n",
    "    else:\n",
    "        raise ValueError('Expected mode in [\\'crop\\', \\'drop\\'], but received unsupported augmentation method %s' % mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b29e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2689195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "##################################\n",
    "# augment function\n",
    "##################################\n",
    "def batch_augment(images, attention_map, mode='drop', theta=0.4, padding_ratio=0.1, red_p=0.9):\n",
    "    batches, _, imgH, imgW = images.size()\n",
    "\n",
    "    if mode == 'crop':\n",
    "        crop_images = []\n",
    "        for batch_index in range(batches):\n",
    "            atten_map = attention_map[batch_index:batch_index + 1]\n",
    "            if isinstance(theta, tuple):\n",
    "                theta_c = random.uniform(*theta) * atten_map.max()\n",
    "            else:\n",
    "                theta_c = theta * atten_map.max()\n",
    "\n",
    "            crop_mask = F.upsample_bilinear(atten_map, size=(imgH, imgW)) >= theta_c\n",
    "            nonzero_indices = torch.nonzero(crop_mask[0, 0, ...])\n",
    "            height_min = max(int(nonzero_indices[:, 0].min().item() - padding_ratio * imgH), 0)\n",
    "            height_max = min(int(nonzero_indices[:, 0].max().item() + padding_ratio * imgH), imgH)\n",
    "            width_min = max(int(nonzero_indices[:, 1].min().item() - padding_ratio * imgW), 0)\n",
    "            width_max = min(int(nonzero_indices[:, 1].max().item() + padding_ratio * imgW), imgW)\n",
    "\n",
    "            crop_images.append(\n",
    "                F.upsample_bilinear(images[batch_index:batch_index + 1, :, height_min:height_max, width_min:width_max],\n",
    "                                    size=(imgH, imgW)))\n",
    "        crop_images = torch.cat(crop_images, dim=0)\n",
    "        return crop_images\n",
    "\n",
    "    elif mode == 'drop':\n",
    "        drop_masks = []\n",
    "        for batch_index in range(batches):\n",
    "            atten_map = attention_map[batch_index:batch_index + 1]\n",
    "            if isinstance(theta, tuple):\n",
    "                theta_d = random.uniform(*theta) * atten_map.max()\n",
    "            else:\n",
    "                theta_d = theta * atten_map.max()\n",
    "            msk=F.upsample_bilinear(atten_map, size=(imgH, imgW)) < theta_d\n",
    "            q =msk.float()\n",
    "            tense_tensor = torch.tensor(q, device='cuda')\n",
    "            drop_masks.append(torch.where(tense_tensor==0.0, torch.tensor(red_p, device = 'cuda'), tense_tensor))\n",
    "        drop_masks = torch.cat(drop_masks, dim=0)\n",
    "        drop_images = images * drop_masks\n",
    "        return drop_images\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Expected mode in [\\'crop\\', \\'drop\\'], but received unsupported augmentation method %s' % mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dbf904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=torch.rand(5, 3, 448, 448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "415b616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod=resnet50(pretrained=True, pth_path=pretrain_path_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "632c8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modf1=MyEnsemble(SSPCAB(3, reduction_ratio=8), resnet50(pretrained=True, pth_path=pretrain_path_B))\n",
    "# modf2=MyEnsemble(SSPCAB(3, reduction_ratio=4), resnet50(pretrained=True, pth_path=pretrain_path_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fbe685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b= mod(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a873672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e6abf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from networks import Axial_Nets\n",
    "from networks import resnet\n",
    "from config import pretrain_path, coordinates_cat, iou_threshs, window_nums_sum, ratios, N_list\n",
    "import numpy as np\n",
    "# from utils.AOLM import AOLM\n",
    "pretrain_path_B = './models/pretrained/resnet50-19c8e357.pth'\n",
    "# PATH = './models/pretrained/resnet_mura_pr.pth'\n",
    "def nms(scores_np, proposalN, iou_threshs, coordinates):\n",
    "    if not (type(scores_np).__module__ == 'numpy' and len(scores_np.shape) == 2 and scores_np.shape[1] == 1):\n",
    "        raise TypeError('score_np is not right')\n",
    "\n",
    "    windows_num = scores_np.shape[0]\n",
    "    indices_coordinates = np.concatenate((scores_np, coordinates), 1)\n",
    "\n",
    "    indices = np.argsort(indices_coordinates[:, 0])\n",
    "    indices_coordinates = np.concatenate((indices_coordinates, np.arange(0,windows_num).reshape(windows_num,1)), 1)[indices]                  #[339,6]\n",
    "    indices_results = []\n",
    "\n",
    "    res = indices_coordinates\n",
    "\n",
    "    while res.any():\n",
    "        indice_coordinates = res[-1]\n",
    "        indices_results.append(indice_coordinates[5])\n",
    "\n",
    "        if len(indices_results) == proposalN:\n",
    "            return np.array(indices_results).reshape(1,proposalN).astype(np.int64)\n",
    "        res = res[:-1]\n",
    "\n",
    "        # Exclude anchor boxes with selected anchor box whose iou is greater than the threshold\n",
    "        start_max = np.maximum(res[:, 1:3], indice_coordinates[1:3])\n",
    "        end_min = np.minimum(res[:, 3:5], indice_coordinates[3:5])\n",
    "        lengths = end_min - start_max + 1\n",
    "        intersec_map = lengths[:, 0] * lengths[:, 1]\n",
    "        intersec_map[np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)] = 0\n",
    "        iou_map_cur = intersec_map / ((res[:, 3] - res[:, 1] + 1) * (res[:, 4] - res[:, 2] + 1) +\n",
    "                                      (indice_coordinates[3] - indice_coordinates[1] + 1) *\n",
    "                                      (indice_coordinates[4] - indice_coordinates[2] + 1) - intersec_map)\n",
    "        res = res[iou_map_cur <= iou_threshs]\n",
    "\n",
    "    while len(indices_results) != proposalN:\n",
    "        indices_results.append(indice_coordinates[5])\n",
    "\n",
    "    return np.array(indices_results).reshape(1, -1).astype(np.int64)\n",
    "\n",
    "class APPM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(APPM, self).__init__()\n",
    "        self.avgpools = [nn.AvgPool2d(ratios[i], 1) for i in range(len(ratios))]\n",
    "\n",
    "    def forward(self, proposalN, x, ratios, window_nums_sum, N_list, iou_threshs, DEVICE='cuda'):\n",
    "        batch, channels, _, _ = x.size()\n",
    "        avgs = [self.avgpools[i](x) for i in range(len(ratios))]\n",
    "\n",
    "        # feature map sum\n",
    "        fm_sum = [torch.sum(avgs[i], dim=1) for i in range(len(ratios))]\n",
    "\n",
    "        all_scores = torch.cat([fm_sum[i].view(batch, -1, 1) for i in range(len(ratios))], dim=1)\n",
    "        windows_scores_np = all_scores.data.cpu().numpy()\n",
    "        window_scores = torch.from_numpy(windows_scores_np).to(DEVICE).reshape(batch, -1)\n",
    "\n",
    "        # nms\n",
    "        proposalN_indices = []\n",
    "        for i, scores in enumerate(windows_scores_np):\n",
    "            indices_results = []\n",
    "            for j in range(len(window_nums_sum)-1):\n",
    "                indices_results.append(nms(scores[sum(window_nums_sum[:j+1]):sum(window_nums_sum[:j+2])], proposalN=N_list[j], iou_threshs=iou_threshs[j],\n",
    "                                           coordinates=coordinates_cat[sum(window_nums_sum[:j+1]):sum(window_nums_sum[:j+2])]) + sum(window_nums_sum[:j+1]))\n",
    "            # indices_results.reverse()\n",
    "            proposalN_indices.append(np.concatenate(indices_results, 1))   # reverse\n",
    "\n",
    "        proposalN_indices = np.array(proposalN_indices).reshape(batch, proposalN)\n",
    "        proposalN_indices = torch.from_numpy(proposalN_indices).to(DEVICE)\n",
    "        proposalN_windows_scores = torch.cat(\n",
    "            [torch.index_select(all_score, dim=0, index=proposalN_indices[i]) for i, all_score in enumerate(all_scores)], 0).reshape(\n",
    "            batch, proposalN)\n",
    "\n",
    "        return proposalN_indices, proposalN_windows_scores, window_scores\n",
    "\n",
    "class MainNet(nn.Module):\n",
    "    def __init__(self, proposalN, num_classes, channels, theta, red_p):\n",
    "       \n",
    "        super(MainNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.proposalN = proposalN\n",
    "        self.M=3\n",
    "        self.theta=theta\n",
    "        self.red_p = red_p\n",
    "        self.SSPCAB_Block = SSPCAB(2048)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "#         self.pretrained_model =Net()\n",
    "#         self.pretrained_model = axial50s(k=56)\n",
    "\n",
    "        self.pretrained_model_A = resnet.resnet50(pretrained=True, pth_path=pretrain_path)\n",
    "        self.pretrained_model_B = resnet50(pretrained=True, pth_path=pretrain_path_B)\n",
    "        self.rawcls_net = nn.Linear(channels, num_classes)\n",
    "        self.APPM = APPM()\n",
    "# (self, layers, output_dim, heads, input_resolution=448, width=64)\n",
    "    def forward(self, x, epoch, batch_idx, status='test', DEVICE='cuda'):\n",
    "#         print(x.shape)\n",
    "        att_out=x\n",
    "#         att_out=batch_augment(x, torch.sum(self.pretrained_model_A(x)[-1], dim=1, keepdim=True),\n",
    "#                               mode='drop', theta=self.theta, red_p=self.red_p)\n",
    "#         print(att_out.shape)\n",
    "        fm1 = self.pretrained_model_B(att_out)\n",
    "        fm2 = self.SSPCAB_Block(fm1)\n",
    "        embeeding = self.avgpool(fm2)\n",
    "        embeeding = embeeding.view(embeeding.size(0), -1)\n",
    "        embeeding = self.dropout(embeeding)\n",
    "        batch_size, channel_size, side_size, _ = fm2.shape\n",
    "        assert channel_size == 2048\n",
    "        \n",
    "\n",
    "        # raw branch\n",
    "        raw_logits = self.rawcls_net(embeeding)\n",
    "        \n",
    "#         print(\"raw_logits\",raw_logits)\n",
    "#         y=raw_logits.argmax(dim=-1)\n",
    "\n",
    "        #SCDA\n",
    "#         coordinats=torch.tensor(TSCM(tscams,y,x,batch_size))\n",
    "        coordinates = torch.tensor(AOLM(fm1.detach(), fm2.detach()))\n",
    "#         print(\"coordinate\",coordinates)\n",
    "\n",
    "        local_imgs = torch.zeros([batch_size, 3, 448, 448]).to(DEVICE)  # [N, 3, 448, 448]\n",
    "        for i in range(batch_size):\n",
    "            [x0, y0, x1, y1] = coordinates[i]\n",
    "            local_imgs[i:i + 1] = F.interpolate(att_out[i:i + 1, :, x0:(x1+1), y0:(y1+1)], size=(448, 448),\n",
    "                                                mode='bilinear', align_corners=True)  # [N, 3, 224, 224]\n",
    "        local_fm1 = self.pretrained_model_B(local_imgs.detach())  # [N, 2048]\n",
    "        local_fm = self.SSPCAB_Block(local_fm1)\n",
    "        local_embeddings = self.avgpool(local_fm)\n",
    "        local_embeddings = local_embeddings.view(local_embeddings.size(0), -1)\n",
    "        local_embeddings = self.dropout(local_embeddings)\n",
    "        local_logits = self.rawcls_net(local_embeddings)  # [N, 2]\n",
    "        #To find final Local image consist of object\n",
    "        \n",
    "        \n",
    "#         final_coordinates = torch.tensor(AOLM(fm.detach(), tscams.detach()))\n",
    "#         final_local_imgs = torch.zeros([batch_size, 3, 448, 448]).to(DEVICE)  # [N, 3, 448, 448]\n",
    "#         for i in range(batch_size):\n",
    "#             [x0, y0, x1, y1] = final_coordinates[i]\n",
    "#             final_local_imgs[i:i + 1] = F.interpolate(att_out[i:i + 1, :, x0:(x1+1), y0:(y1+1)], size=(448, 448),\n",
    "#                                                 mode='bilinear', align_corners=True)  # [N, 3, 224, 224]\n",
    "#         final_local_fm, final_local_embeddings, _, _ = self.pretrained_model_B(final_local_imgs.detach())  # [N, 2048]\n",
    "#         final_local_logits = self.rawcls_net(final_local_embeddings)  # [N, 2]\n",
    "        proposalN_indices, proposalN_windows_scores, window_scores \\\n",
    "            = self.APPM(self.proposalN, local_fm.detach(), ratios, window_nums_sum, N_list, iou_threshs, DEVICE)\n",
    "\n",
    "        if status == \"train\":\n",
    "            # window_imgs cls\n",
    "            window_imgs = torch.zeros([batch_size, self.proposalN, 3, 224, 224]).to(DEVICE)  # [N, 4, 3, 224, 224]\n",
    "            wnds=[]\n",
    "            for i in range(batch_size):\n",
    "                wnd=[]\n",
    "                for j in range(self.proposalN):\n",
    "                    [x0, y0, x1, y1] = coordinates_cat[proposalN_indices[i, j]]\n",
    "                    window_imgs[i:i + 1, j] = F.interpolate(local_imgs[i:i + 1, :, x0:(x1 + 1), y0:(y1 + 1)], size=(224, 224),\n",
    "                                                                mode='bilinear',\n",
    "                                                                align_corners=True)  # [N, 4, 3, 224, 224]\n",
    "                    wnd.append([x0, y0, x1, y1])\n",
    "                wnds.append(wnd)\n",
    "                   \n",
    "            window_imgs = window_imgs.reshape(batch_size * self.proposalN, 3, 224, 224)  # [N*4, 3, 224, 224]\n",
    "            window_fm = self.pretrained_model_B(window_imgs.detach())  # [N*4, 2048]\n",
    "            window_fm = self.SSPCAB_Block(window_fm)\n",
    "            window_fm = self.avgpool(window_fm)\n",
    "            window_fm = window_fm.view(window_fm.size(0), -1)\n",
    "            window_embeddings = self.dropout(window_fm)         \n",
    " \n",
    "            proposalN_windows_logits = self.rawcls_net(window_embeddings)  # [N* 4, 200]\n",
    "        else:\n",
    "            proposalN_windows_logits = torch.zeros([batch_size * self.proposalN, self.num_classes]).to(DEVICE)\n",
    "\n",
    "        return proposalN_windows_scores, proposalN_windows_logits, proposalN_indices, \\\n",
    "    window_scores, coordinates, raw_logits, local_logits, local_imgs, att_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1a302cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_imgs(org, ot, codd):\n",
    "    size=(codd[3]-codd[1], codd[2]-codd[0])\n",
    "    image_boxes2 = Image.fromarray(ot)\n",
    "    image_boxes2 = image_boxes2.resize(size)\n",
    "    imgo = Image.fromarray(org)\n",
    "    imgo.paste(image_boxes2, (codd[1], codd[0]))\n",
    "    return imgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666364d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63080361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bea1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6128413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import CohenKappa\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchmetrics.functional import auc\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def classification_results(pre, tar, stat):\n",
    "    confmat = ConfusionMatrix(num_classes=2)\n",
    "    cohenkappa = CohenKappa(num_classes=2)\n",
    "    acc=Accuracy()\n",
    "    \n",
    "    print(\"*****************************\")\n",
    "    print(stat)\n",
    "    print(\"Confusion Matrix\", confmat(tar, pre).numpy())\n",
    "#     print(\"cohenkappa score\", cohenkappa(tar, pre).numpy())\n",
    "#     print(\"AUC\", roc_auc_score(tar, pre))\n",
    "#     print(\"accuracy\", acc(tar, pre).numpy())\n",
    "#     print(\"MCC\", matthews_corrcoef(tar, pre))\n",
    "    print(\"*****************************\")\n",
    "    return cohenkappa(tar, pre).numpy(), roc_auc_score(tar, pre), matthews_corrcoef(tar, pre)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a1481e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6b4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83895281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b3f689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, dataloaders, dataset_sizes):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        p=[]\n",
    "        q=[]\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "#                 inputs, labels= data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)[-1]\n",
    "                    #              output = model(input)\n",
    "                    if isinstance(outputs, tuple): # <-- inception output is a tuple (x, aux)\n",
    "                        outputs = outputs[0]  \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "#                     print(preds)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "#                 print(preds)\n",
    "#                 print((labels.data))\n",
    "                p.append(preds)\n",
    "                q.append(labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            Q=torch.cat(q).reshape(-1).cpu()\n",
    "            P=torch.cat(p).reshape(-1).cpu()\n",
    "#             print(P)\n",
    "#             print(Q)\n",
    "            classification_results(P, Q, phase)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "#         print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return best_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97803722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "from config import coordinates_cat, proposalN, set, vis_num\n",
    "from utils.cal_iou import calculate_iou\n",
    "from utils.vis import image_with_boxes, image_with_box\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "CFR=True\n",
    "def eval(model, testloader, criterion, status, save_path, epoch):\n",
    "    model.eval()\n",
    "    print('Evaluating')\n",
    "\n",
    "    raw_loss_sum = 0\n",
    "    local_loss_sum = 0\n",
    "#     final_local_loss_sum=0\n",
    "    windowscls_loss_sum = 0\n",
    "    total_loss_sum = 0\n",
    "    iou_corrects = 0\n",
    "    raw_correct = 0\n",
    "    local_correct = 0\n",
    "#     final_local_correct=0\n",
    "    obtain_row=[]\n",
    "#     obtain_final_local=[]\n",
    "    obtain_local=[]\n",
    "    desire=[]\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm(testloader)):\n",
    "            if set == 'CUB':\n",
    "                images, labels, boxes, scale = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "            desire.append(labels)\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            proposalN_windows_score,proposalN_windows_logits, indices, \\\n",
    "            window_scores, coordinates, raw_logits, local_logits, local_imgs, \\\n",
    "            att_out = model(images, epoch, i, status)\n",
    "            raw_loss = criterion(raw_logits, labels)\n",
    "            local_loss = criterion(local_logits, labels)\n",
    "#             final_local_loss = criterion(final_local_logits,labels)\n",
    "            windowscls_loss = criterion(proposalN_windows_logits,\n",
    "                                        labels.unsqueeze(1).repeat(1, proposalN).view(-1))\n",
    "\n",
    "            total_loss = raw_loss + local_loss + windowscls_loss\n",
    "\n",
    "            raw_loss_sum += raw_loss.item()\n",
    "            local_loss_sum += local_loss.item()\n",
    "#             final_local_loss_sum += final_local_loss.item()\n",
    "            windowscls_loss_sum += windowscls_loss.item()\n",
    "\n",
    "            total_loss_sum += total_loss.item()\n",
    "            if set == 'CUB':\n",
    "                # computer resized coordinates of boxes\n",
    "                boxes_coor = boxes.float()\n",
    "                resized_boxes = torch.cat([(boxes_coor[:,0] * scale[:, 0]).unsqueeze(1) ,(boxes_coor[:,1] * scale[:, 1]).unsqueeze(1),\n",
    "                                           (boxes_coor[:,2] * scale[:, 0]).unsqueeze(1), (boxes_coor[:,3] * scale[:, 1]).unsqueeze(1)], dim=1)\n",
    "                resized_coor = torch.cat([resized_boxes[:,0].unsqueeze(1) ,resized_boxes[:,1].unsqueeze(1),\n",
    "                                           (resized_boxes[:,0] + resized_boxes[:,2]).unsqueeze(1), (resized_boxes[:,1]+resized_boxes[:,3]).unsqueeze(1)], dim=1).round().int()\n",
    "\n",
    "\n",
    "                iou = calculate_iou(coordinates.cpu().numpy(), resized_coor.numpy())\n",
    "                iou_corrects += np.sum(iou >= 0.5)\n",
    "                with SummaryWriter(log_dir=os.path.join(save_path, 'log'), comment='test') as writer:\n",
    "                    writer.add_scalar('Test/PCP', iou_corrects, epoch)\n",
    "            # Row branch\n",
    "\n",
    "            pred = raw_logits.max(1, keepdim=True)[1]\n",
    "            raw_correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "            obtain_row.append(pred)\n",
    "            # local branch\n",
    "            pred = local_logits.max(1, keepdim=True)[1]\n",
    "            obtain_local.append(pred)\n",
    "            local_correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "            if i == 0:\n",
    "                if set == 'CUB':\n",
    "                    box_coor = resized_coor[:vis_num].numpy()\n",
    "                    pred_coor = coordinates[:vis_num].cpu().numpy()\n",
    "                    with SummaryWriter(log_dir=os.path.join(save_path, 'log'), comment=status + 'raw') as writer:\n",
    "                        cat_imgs = []\n",
    "                        for j, coor in enumerate(box_coor):\n",
    "                            img = image_with_boxes(images[j], [coor])\n",
    "                            img = image_with_boxes(img, [pred_coor[j]], color=(0, 255, 0))\n",
    "                            cat_imgs.append(img)\n",
    "                        cat_imgs = np.concatenate(cat_imgs, axis=1)\n",
    "                        writer.add_images(status + '/' + 'raw image with boxes', cat_imgs, epoch, dataformats='HWC')\n",
    "\n",
    "            \n",
    "#             #final_local\n",
    "#             pred = final_local_logits.max(1, keepdim=True)[1]\n",
    "#             obtain_final_local.append(pred)\n",
    "#             final_local_correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "            # object branch tensorboard\n",
    "            indices_ndarray = indices[:vis_num,:proposalN].cpu().numpy()\n",
    "            if i==0 or i== 1 or i==2:\n",
    "#                 or i== 3 or i==4:\n",
    "                \n",
    "                with SummaryWriter(log_dir=os.path.join(save_path, 'log'), comment=status + 'Final Results') as writer:\n",
    "                    cat_imgs = []\n",
    "                    no_box_imgs=[]\n",
    "                    local_ims=[]\n",
    "#                     final_local_ims=[]\n",
    "                    s_box_imgs=[]\n",
    "                    for j, indice_ndarray in enumerate(indices_ndarray):\n",
    "\n",
    "                        if labels[j]==0:\n",
    "                            results=[]\n",
    "                            att=image_with_boxes(att_out[j])\n",
    "                            im = image_with_boxes(images[j])\n",
    "                            results.append(im)\n",
    "                            results.append(att)\n",
    "                            local_im = image_with_boxes(local_imgs[j])\n",
    "                            results.append(local_im)\n",
    "#                             final_local_im = image_with_boxes(final_local_imgs[j])\n",
    "#                             results.append(final_local_im)\n",
    "                            img = image_with_boxes(local_imgs[j], coordinates_cat[indice_ndarray])\n",
    "                            results.append(img)\n",
    "                            s_box_img=image_with_box(local_imgs[j], coordinates_cat[indice_ndarray])\n",
    "                            results.append(s_box_img)\n",
    "                            fin_res=combine_imgs(im, s_box_img, coordinates[j])\n",
    "                            results.append(fin_res)\n",
    "    #                         print(results)\n",
    "                            results = np.concatenate(results, axis=1)\n",
    "    #                         show_images(results, cols = 1)\n",
    "\n",
    "                            writer.add_images(status + '/' + 'Original images' +'/' + 'Local images'+ '/' +\n",
    "                                              'Object image with windows'+ str(i)+str(j), results, epoch, dataformats='HWC')\n",
    "\n",
    "    raw_loss_avg = raw_loss_sum / (i+1)\n",
    "    local_loss_avg = local_loss_sum / (i+1)\n",
    "#     final_local_loss_avg = final_local_loss_sum / (i+1)\n",
    "    windowscls_loss_avg = windowscls_loss_sum / (i+1)\n",
    "    total_loss_avg = total_loss_sum / (i+1)\n",
    "\n",
    "    raw_accuracy = raw_correct / len(testloader.dataset)\n",
    "    local_accuracy = local_correct / len(testloader.dataset)\n",
    "#     final_local_accuracy = final_local_correct / len(testloader.dataset)\n",
    "\n",
    "    \n",
    "    if CFR==True:\n",
    "        tar=torch.cat(desire).reshape(-1).cpu()\n",
    "        o_r=torch.cat(obtain_row).reshape(-1).cpu()\n",
    "#         o_fl=torch.cat(obtain_final_local).reshape(-1).cpu()\n",
    "        o_l=torch.cat(obtain_local).reshape(-1).cpu()\n",
    "        _, _, _=classification_results(o_r, tar, \"Row\")\n",
    "#         classification_results(o_fl, tar, \"Final_Local\")\n",
    "        C, AC, MAT=classification_results(o_l, tar, \"Local\")\n",
    "    return raw_loss_avg, windowscls_loss_avg, total_loss_avg, raw_accuracy, local_accuracy, local_loss_avg, C, AC, MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "caf6c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MainNet(proposalN=proposalN, num_classes=num_classes, channels=2048, theta=(0.6), red_p=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa4dc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test=torch.rand(5, 3, 448,448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "228677a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test=model.modf1.modelB(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc41e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565e523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e12fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74e3d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "from config import max_checkpoint_num, proposalN, eval_trainset, set\n",
    "# from utils.eval_model import eval\n",
    "\n",
    "def train(model,\n",
    "          trainloader,\n",
    "          testloader,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          scheduler,\n",
    "          save_path,\n",
    "          start_epoch,\n",
    "          end_epoch,\n",
    "          num_epochs,\n",
    "          save_interval):\n",
    "    eval_trainset=False\n",
    "#     dataset_sizes = {['train', 'val'][x]: [len(trainloader.dataset),len(testloader.dataset)][x] for x in range(len(['train', 'val']))}\n",
    "    \n",
    "#     dataloaders = {['train', 'val'][x]: [trainloader,testloader][x] for x in range(len(['train', 'val']))}\n",
    "    \n",
    "#     print(\"Exploring...\")\n",
    "#     if start_epoch < 2:\n",
    "#         best_model_wts = train_model(model.pretrained_model_B, criterion, optimizer, scheduler, num_epochs,\n",
    "#                                            dataloaders, dataset_sizes)\n",
    "#         model.pretrained_model_B.load_state_dict(best_model_wts)\n",
    "#     print(\"Expolaration done.\")\n",
    "    for epoch in range(start_epoch + 1, end_epoch + 1):\n",
    "        model.train()\n",
    "        \n",
    "        print('Training %d epoch' % epoch)\n",
    "        \n",
    "        lr = next(iter(optimizer.param_groups))['lr']\n",
    "\n",
    "        for i, data in enumerate(tqdm(trainloader, 0)):\n",
    "            if set == 'CUB':\n",
    "                images, labels, _, _ = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            proposalN_windows_score, proposalN_windows_logits, indices, \\\n",
    "            window_scores, _, raw_logits, local_logits, local_imgs, _ = model(images, epoch, i, 'train')\n",
    "\n",
    "            raw_loss = criterion(raw_logits, labels)\n",
    "            local_loss = criterion(local_logits, labels)\n",
    "#             final_local_loss=criterion(final_local_logits, labels)\n",
    "            windowscls_loss = criterion(proposalN_windows_logits,\n",
    "                               labels.unsqueeze(1).repeat(1, proposalN).view(-1))\n",
    "\n",
    "            if epoch < 2:\n",
    "                total_loss = raw_loss\n",
    "            else:\n",
    "                total_loss = raw_loss + local_loss + windowscls_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "#         evaluation every epoch\n",
    "        if eval_trainset:\n",
    "            raw_loss_avg, windowscls_loss_avg, total_loss_avg, raw_accuracy, local_accuracy, local_loss_avg, C, AC, MAT = eval(model, trainloader, criterion, 'train', save_path, epoch)\n",
    "            \n",
    "\n",
    "            print(\n",
    "                'Train set: raw accuracy: {:.2f}%, local accuracy: {:.2f}%, CohenKappa: {:.2f}%, AUC: {:.2f}%, MCC: {:.2f}%'.format(100. * raw_accuracy, 100. * local_accuracy, C, AC, MAT ))\n",
    "\n",
    "            # tensorboard\n",
    "            with SummaryWriter(log_dir=os.path.join(save_path, 'log'), comment='train') as writer:\n",
    "\n",
    "                writer.add_scalar('Train/learning rate', lr, epoch)\n",
    "                writer.add_scalar('Train/raw_accuracy', raw_accuracy, epoch)\n",
    "                writer.add_scalar('Train/local_accuracy', local_accuracy, epoch)\n",
    "                writer.add_scalar('Train/CohenKappa', C, epoch)\n",
    "                writer.add_scalar('Train/raw_loss_avg', raw_loss_avg, epoch)\n",
    "                writer.add_scalar('Train/local_loss_avg', local_loss_avg, epoch)\n",
    "                writer.add_scalar('Train/AUC', AC, epoch)\n",
    "                writer.add_scalar('Train/MCC', MAT, epoch)\n",
    "                writer.add_scalar('Train/windowscls_loss_avg', windowscls_loss_avg, epoch)\n",
    "                writer.add_scalar('Train/total_loss_avg', total_loss_avg, epoch)\n",
    "                \n",
    "\n",
    "        # eval testset\n",
    "        raw_loss_avg, windowscls_loss_avg, total_loss_avg, raw_accuracy, local_accuracy, local_loss_avg, C, AC, MAT = eval(model, testloader, criterion, 'test', save_path, epoch)\n",
    "        print('Test set: raw accuracy: {:.2f}%, local accuracy: {:.2f}%, CohenKappa: {:.2f}%, AUC: {:.2f}%, MCC: {:.2f}%'.format(100. * raw_accuracy, 100. * local_accuracy, C, AC, MAT ))\n",
    "\n",
    "        # tensorboard\n",
    "        with SummaryWriter(log_dir=os.path.join(save_path, 'log'), comment='test') as writer:\n",
    "            writer.add_scalar('Test/raw_accuracy', raw_accuracy, epoch)\n",
    "            writer.add_scalar('Test/local_accuracy', local_accuracy, epoch)\n",
    "            writer.add_scalar('Test/CohenKappa', C, epoch)\n",
    "            writer.add_scalar('Test/raw_loss_avg', raw_loss_avg, epoch)\n",
    "            writer.add_scalar('Test/local_loss_avg', local_loss_avg, epoch)\n",
    "            writer.add_scalar('Test/AUC', AC, epoch)\n",
    "            writer.add_scalar('Test/MCC', MAT, epoch)\n",
    "            writer.add_scalar('Test/windowscls_loss_avg', windowscls_loss_avg, epoch)\n",
    "            writer.add_scalar('Test/total_loss_avg', total_loss_avg, epoch)\n",
    "\n",
    "        # save checkpoint\n",
    "        if (epoch % save_interval == 0) or (epoch == end_epoch):\n",
    "            print('Saving checkpoint')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'learning_rate': lr,\n",
    "            }, os.path.join(save_path, 'epoch' + str(epoch) + '.pth'))\n",
    "\n",
    "        # Limit the number of checkpoints to less than or equal to max_checkpoint_num,\n",
    "        # and delete the redundant ones\n",
    "        checkpoint_list = [os.path.basename(path) for path in glob.glob(os.path.join(save_path, '*.pth'))]\n",
    "        if len(checkpoint_list) == max_checkpoint_num + 1:\n",
    "            idx_list = [int(name.replace('epoch', '').replace('.pth', '')) for name in checkpoint_list]\n",
    "            min_idx = min(idx_list)\n",
    "            os.remove(os.path.join(save_path, 'epoch' + str(min_idx) + '.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5083452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "def tenssor2array(images):\n",
    "    if type(images) is not np.ndarray:\n",
    "        image = images.clone().detach()\n",
    "\n",
    "        rgbN = [(255, 0, 0), (255, 165, 0), (255, 255, 0), (0, 255, 0), (0, 255, 0), (0, 255, 0), (0, 255, 0)]\n",
    "\n",
    "        # Anti-normalization\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        image[0] = image[0] * std[0] + mean[0]\n",
    "        image[1] = image[1] * std[1] + mean[1]\n",
    "        image[2] = image[2].mul(std[2]) + mean[2]\n",
    "        image = image.mul(255).byte()\n",
    "\n",
    "        image = image.data.cpu().numpy()\n",
    "\n",
    "        image.astype(np.uint8)\n",
    "\n",
    "        image = np.transpose(image, (1, 2, 0))  # CHW --> HWC\n",
    "        \n",
    "    return im.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a019599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.8\n",
    "GAMMA = 2\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n",
    "\n",
    "        \n",
    "        #first compute binary cross-entropy \n",
    "        BCE = nn.CrossEntropyLoss()(inputs, targets)\n",
    "        BCE_EXP = torch.exp(-BCE)\n",
    "        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n",
    "                       \n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c11612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "163695f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53f0167d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "346e34f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cce4b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "567d4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TUMOR():\n",
    "    def __init__(self, input_size, root, is_train=True, data_len=None):\n",
    "        self.input_size = input_size\n",
    "        self.root = root\n",
    "#         self.transform = transform\n",
    "#         self.to_pil = transforms.ToPILImage()\n",
    "        self.is_train = is_train\n",
    "        train_img_path = os.path.join(self.root)\n",
    "        test_img_path = os.path.join(self.root)\n",
    "        train_label_file = open(os.path.join(self.root, 'train.txt'))\n",
    "        test_label_file = open(os.path.join(self.root, 'test.txt'))\n",
    "        train_img_label = []\n",
    "        test_img_label = []\n",
    "        for line in train_label_file:\n",
    "            train_img_label.append([os.path.join(train_img_path, line[:-2]), int(line[-2])])\n",
    "        for line in test_label_file:\n",
    "            test_img_label.append([os.path.join(test_img_path, line[:-2]), int(line[-2])])\n",
    "        self.train_img_label = train_img_label[:data_len]\n",
    "        self.test_img_label = test_img_label[:data_len]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_train:\n",
    "            img, target = imageio.imread(self.train_img_label[index][0]), self.train_img_label[index][1]\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            img = Image.fromarray(img, mode='RGB')\n",
    "\n",
    "            img = transforms.Resize((self.input_size, self.input_size), Image.Resampling.BILINEAR)(img)\n",
    "            # img = transforms.RandomResizedCrop(size=self.input_size,scale=(0.4, 0.75),ratio=(0.5,1.5))(img)\n",
    "            # img = transforms.RandomCrop(self.input_size)(img)\n",
    "            img = transforms.RandomHorizontalFlip()(img)\n",
    "            img = transforms.ColorJitter(brightness=0.2, contrast=0.2)(img)\n",
    "\n",
    "            img = transforms.ToTensor()(img)\n",
    "            img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n",
    "\n",
    "        else:\n",
    "            img, target = imageio.imread(self.test_img_label[index][0]), self.test_img_label[index][1]\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            img = Image.fromarray(img, mode='RGB')\n",
    "            img = transforms.Resize((self.input_size, self.input_size), Image.BILINEAR)(img)\n",
    "            # img = transforms.CenterCrop(self.input_size)(img)\n",
    "            img = transforms.ToTensor()(img)\n",
    "            img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n",
    "\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_img_label)\n",
    "        else:\n",
    "            return len(self.test_img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c41e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=TUMOR(input_size, root, is_train=True, data_len=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19d1b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_label_file:\n",
    "#     print(os.path.join(train_img_path, line[:-2]), int(line[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8929f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test=torch.rand(1, 3, 448, 448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e00a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d=model.pretrained_model_B(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc176589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abnormality'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d54b4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader, testloader = read_dataset(input_size, batch_size, root, set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45c09f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(trainloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbf649ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MainNet(proposalN=proposalN, num_classes=num_classes, channels=2048, theta=(0.6), red_p=0.15)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64d75b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader, testloader = read_dataset(input_size, batch_size, root, set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "832160d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_x, _ = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b10f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display image and label.\n",
    "# train_features, train_labels = next(iter(trainloader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# img = train_features[0].squeeze()\n",
    "# label = train_labels[0]\n",
    "# # plt.imshow(img, cmap=\"gray\")\n",
    "# # plt.show()\n",
    "# print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a37e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f52b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04d3432b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Abnormality trainset\n",
      "Loading Abnormality testset\n",
      "Load model from ./checkpoint/Abnormality\\fm1fm2attention1\\epoch28.pth\n",
      "Resume from ./checkpoint/Abnormality\\fm1fm2attention1\\epoch28.pth\n",
      "Training 29 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:34<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3930  185]\n",
      " [ 106  669]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3856  194]\n",
      " [ 180  660]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.05%, local accuracy: 92.35%, CohenKappa: 0.73%, AUC: 0.86%, MCC: 0.73%\n",
      "Saving checkpoint\n",
      "Training 30 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:25<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:22<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3833   99]\n",
      " [ 203  755]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3869  207]\n",
      " [ 167  647]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 93.82%, local accuracy: 92.35%, CohenKappa: 0.73%, AUC: 0.86%, MCC: 0.73%\n",
      "Saving checkpoint\n",
      "Training 31 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:24<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:22<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3852  119]\n",
      " [ 184  735]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3829  169]\n",
      " [ 207  685]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 93.80%, local accuracy: 92.31%, CohenKappa: 0.74%, AUC: 0.88%, MCC: 0.74%\n",
      "Saving checkpoint\n",
      "Training 32 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:21<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:22<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3977  144]\n",
      " [  59  710]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3877  188]\n",
      " [ 159  666]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.85%, local accuracy: 92.90%, CohenKappa: 0.75%, AUC: 0.87%, MCC: 0.75%\n",
      "Saving checkpoint\n",
      "Training 33 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:29<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3672   60]\n",
      " [ 364  794]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3591  116]\n",
      " [ 445  738]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 91.33%, local accuracy: 88.53%, CohenKappa: 0.65%, AUC: 0.88%, MCC: 0.67%\n",
      "Saving checkpoint\n",
      "Training 34 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:38<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3858  140]\n",
      " [ 178  714]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3855  204]\n",
      " [ 181  650]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 93.50%, local accuracy: 92.13%, CohenKappa: 0.72%, AUC: 0.86%, MCC: 0.72%\n",
      "Saving checkpoint\n",
      "Training 35 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:42<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3864  111]\n",
      " [ 172  743]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3811  178]\n",
      " [ 225  676]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.21%, local accuracy: 91.76%, CohenKappa: 0.72%, AUC: 0.87%, MCC: 0.72%\n",
      "Saving checkpoint\n",
      "Training 36 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:52<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3931  146]\n",
      " [ 105  708]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3891  180]\n",
      " [ 145  674]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.87%, local accuracy: 93.35%, CohenKappa: 0.77%, AUC: 0.88%, MCC: 0.77%\n",
      "Saving checkpoint\n",
      "Training 37 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:49<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3909   99]\n",
      " [ 127  755]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3831  158]\n",
      " [ 205  696]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.38%, local accuracy: 92.58%, CohenKappa: 0.75%, AUC: 0.88%, MCC: 0.75%\n",
      "Saving checkpoint\n",
      "Training 38 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:50<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3684   49]\n",
      " [ 352  805]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3550   89]\n",
      " [ 486  765]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 91.80%, local accuracy: 88.24%, CohenKappa: 0.66%, AUC: 0.89%, MCC: 0.67%\n",
      "Saving checkpoint\n",
      "Training 39 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:52<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3678   54]\n",
      " [ 358  800]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3672  117]\n",
      " [ 364  737]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 91.57%, local accuracy: 90.16%, CohenKappa: 0.69%, AUC: 0.89%, MCC: 0.70%\n",
      "Saving checkpoint\n",
      "Training 40 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:54<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3904  123]\n",
      " [ 132  731]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3832  190]\n",
      " [ 204  664]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.79%, local accuracy: 91.94%, CohenKappa: 0.72%, AUC: 0.86%, MCC: 0.72%\n",
      "Saving checkpoint\n",
      "Training 41 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:01<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3703   37]\n",
      " [ 333  817]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3748  135]\n",
      " [ 288  719]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 92.43%, local accuracy: 91.35%, CohenKappa: 0.72%, AUC: 0.89%, MCC: 0.72%\n",
      "Saving checkpoint\n",
      "Training 42 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:01<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3643   60]\n",
      " [ 393  794]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3617  115]\n",
      " [ 419  739]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 90.74%, local accuracy: 89.08%, CohenKappa: 0.67%, AUC: 0.88%, MCC: 0.68%\n",
      "Saving checkpoint\n",
      "Training 43 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:55<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3842   77]\n",
      " [ 194  777]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3779  152]\n",
      " [ 257  702]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.46%, local accuracy: 91.64%, CohenKappa: 0.72%, AUC: 0.88%, MCC: 0.73%\n",
      "Saving checkpoint\n",
      "Training 44 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:06<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3888  109]\n",
      " [ 148  745]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3792  145]\n",
      " [ 244  709]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.74%, local accuracy: 92.04%, CohenKappa: 0.74%, AUC: 0.88%, MCC: 0.74%\n",
      "Saving checkpoint\n",
      "Training 45 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:58<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3690   54]\n",
      " [ 346  800]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3531   99]\n",
      " [ 505  755]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 91.82%, local accuracy: 87.65%, CohenKappa: 0.64%, AUC: 0.88%, MCC: 0.66%\n",
      "Saving checkpoint\n",
      "Training 46 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:56<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3889   84]\n",
      " [ 147  770]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3802  127]\n",
      " [ 234  727]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.28%, local accuracy: 92.62%, CohenKappa: 0.76%, AUC: 0.90%, MCC: 0.76%\n",
      "Saving checkpoint\n",
      "Training 47 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:51<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3855   94]\n",
      " [ 181  760]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3755  132]\n",
      " [ 281  722]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.38%, local accuracy: 91.55%, CohenKappa: 0.73%, AUC: 0.89%, MCC: 0.73%\n",
      "Saving checkpoint\n",
      "Training 48 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:52<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3801   65]\n",
      " [ 235  789]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3899  180]\n",
      " [ 137  674]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 93.87%, local accuracy: 93.52%, CohenKappa: 0.77%, AUC: 0.88%, MCC: 0.77%\n",
      "Saving checkpoint\n",
      "Training 49 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:42<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3623   58]\n",
      " [ 413  796]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3471   85]\n",
      " [ 565  769]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 90.37%, local accuracy: 86.71%, CohenKappa: 0.62%, AUC: 0.88%, MCC: 0.65%\n",
      "Saving checkpoint\n",
      "Training 50 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:39<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3564   36]\n",
      " [ 472  818]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3698  107]\n",
      " [ 338  747]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 89.61%, local accuracy: 90.90%, CohenKappa: 0.71%, AUC: 0.90%, MCC: 0.72%\n",
      "Saving checkpoint\n",
      "Training 51 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:37<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4002  215]\n",
      " [  34  639]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3987  243]\n",
      " [  49  611]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.91%, local accuracy: 94.03%, CohenKappa: 0.77%, AUC: 0.85%, MCC: 0.78%\n",
      "Saving checkpoint\n",
      "Training 52 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:32<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3882   88]\n",
      " [ 154  766]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3850  156]\n",
      " [ 186  698]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.05%, local accuracy: 93.01%, CohenKappa: 0.76%, AUC: 0.89%, MCC: 0.76%\n",
      "Saving checkpoint\n",
      "Training 53 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:27<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3975   87]\n",
      " [  61  767]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3803  123]\n",
      " [ 233  731]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.97%, local accuracy: 92.72%, CohenKappa: 0.76%, AUC: 0.90%, MCC: 0.76%\n",
      "Saving checkpoint\n",
      "Training 54 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:30<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3847   43]\n",
      " [ 189  811]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3759   97]\n",
      " [ 277  757]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.26%, local accuracy: 92.35%, CohenKappa: 0.76%, AUC: 0.91%, MCC: 0.76%\n",
      "Saving checkpoint\n",
      "Training 55 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:34<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4002  202]\n",
      " [  34  652]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3962  192]\n",
      " [  74  662]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.17%, local accuracy: 94.56%, CohenKappa: 0.80%, AUC: 0.88%, MCC: 0.80%\n",
      "Saving checkpoint\n",
      "Training 56 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:35<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3934   66]\n",
      " [ 102  788]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3863  136]\n",
      " [ 173  718]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.56%, local accuracy: 93.68%, CohenKappa: 0.78%, AUC: 0.90%, MCC: 0.78%\n",
      "Saving checkpoint\n",
      "Training 57 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:37<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3961   97]\n",
      " [  75  757]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3845  112]\n",
      " [ 191  742]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.48%, local accuracy: 93.80%, CohenKappa: 0.79%, AUC: 0.91%, MCC: 0.79%\n",
      "Saving checkpoint\n",
      "Training 58 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:29<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3704   40]\n",
      " [ 332  814]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3650   93]\n",
      " [ 386  761]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 92.39%, local accuracy: 90.20%, CohenKappa: 0.70%, AUC: 0.90%, MCC: 0.71%\n",
      "Saving checkpoint\n",
      "Training 59 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:36<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3994  120]\n",
      " [  42  734]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3966  179]\n",
      " [  70  675]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.69%, local accuracy: 94.91%, CohenKappa: 0.81%, AUC: 0.89%, MCC: 0.82%\n",
      "Saving checkpoint\n",
      "Training 60 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:33<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4001  128]\n",
      " [  35  726]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3913  126]\n",
      " [ 123  728]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.67%, local accuracy: 94.91%, CohenKappa: 0.82%, AUC: 0.91%, MCC: 0.82%\n",
      "Saving checkpoint\n",
      "Training 61 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:28<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3967   83]\n",
      " [  69  771]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3874  141]\n",
      " [ 162  713]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.89%, local accuracy: 93.80%, CohenKappa: 0.79%, AUC: 0.90%, MCC: 0.79%\n",
      "Saving checkpoint\n",
      "Training 62 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:27<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3938   88]\n",
      " [  98  766]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3813  122]\n",
      " [ 223  732]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.20%, local accuracy: 92.94%, CohenKappa: 0.77%, AUC: 0.90%, MCC: 0.77%\n",
      "Saving checkpoint\n",
      "Training 63 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:29<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3986  132]\n",
      " [  50  722]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3903  154]\n",
      " [ 133  700]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.28%, local accuracy: 94.13%, CohenKappa: 0.79%, AUC: 0.89%, MCC: 0.79%\n",
      "Saving checkpoint\n",
      "Training 64 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:34<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3929   76]\n",
      " [ 107  778]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3837  118]\n",
      " [ 199  736]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.26%, local accuracy: 93.52%, CohenKappa: 0.78%, AUC: 0.91%, MCC: 0.78%\n",
      "Saving checkpoint\n",
      "Training 65 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:46<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3908   70]\n",
      " [ 128  784]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3841  122]\n",
      " [ 195  732]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.95%, local accuracy: 93.52%, CohenKappa: 0.78%, AUC: 0.90%, MCC: 0.78%\n",
      "Saving checkpoint\n",
      "Training 66 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:51<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:26<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3919   67]\n",
      " [ 117  787]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3765  109]\n",
      " [ 271  745]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.24%, local accuracy: 92.23%, CohenKappa: 0.75%, AUC: 0.90%, MCC: 0.75%\n",
      "Saving checkpoint\n",
      "Training 67 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:06<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4011  202]\n",
      " [  25  652]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3958  213]\n",
      " [  78  641]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.36%, local accuracy: 94.05%, CohenKappa: 0.78%, AUC: 0.87%, MCC: 0.78%\n",
      "Saving checkpoint\n",
      "Training 68 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:00<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4010  135]\n",
      " [  26  719]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3981  173]\n",
      " [  55  681]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.71%, local accuracy: 95.34%, CohenKappa: 0.83%, AUC: 0.89%, MCC: 0.83%\n",
      "Saving checkpoint\n",
      "Training 69 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:02<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3893   60]\n",
      " [ 143  794]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3699   81]\n",
      " [ 337  773]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.85%, local accuracy: 91.45%, CohenKappa: 0.73%, AUC: 0.91%, MCC: 0.74%\n",
      "Saving checkpoint\n",
      "Training 70 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:58<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3877   55]\n",
      " [ 159  799]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3741   75]\n",
      " [ 295  779]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.62%, local accuracy: 92.43%, CohenKappa: 0.76%, AUC: 0.92%, MCC: 0.77%\n",
      "Saving checkpoint\n",
      "Training 71 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:59<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3972   99]\n",
      " [  64  755]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3932  134]\n",
      " [ 104  720]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.67%, local accuracy: 95.13%, CohenKappa: 0.83%, AUC: 0.91%, MCC: 0.83%\n",
      "Saving checkpoint\n",
      "Training 72 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:00<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3955   96]\n",
      " [  81  758]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3882  108]\n",
      " [ 154  746]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.38%, local accuracy: 94.64%, CohenKappa: 0.82%, AUC: 0.92%, MCC: 0.82%\n",
      "Saving checkpoint\n",
      "Training 73 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:02<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3938   97]\n",
      " [  98  757]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3898  139]\n",
      " [ 138  715]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.01%, local accuracy: 94.34%, CohenKappa: 0.80%, AUC: 0.90%, MCC: 0.80%\n",
      "Saving checkpoint\n",
      "Training 74 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:08<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3942  101]\n",
      " [  94  753]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3856  124]\n",
      " [ 180  730]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.01%, local accuracy: 93.78%, CohenKappa: 0.79%, AUC: 0.91%, MCC: 0.79%\n",
      "Saving checkpoint\n",
      "Training 75 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:03<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3626   22]\n",
      " [ 410  832]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3599   61]\n",
      " [ 437  793]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 91.17%, local accuracy: 89.82%, CohenKappa: 0.70%, AUC: 0.91%, MCC: 0.72%\n",
      "Saving checkpoint\n",
      "Training 76 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:05<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3882   65]\n",
      " [ 154  789]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3791   76]\n",
      " [ 245  778]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 95.52%, local accuracy: 93.44%, CohenKappa: 0.79%, AUC: 0.93%, MCC: 0.79%\n",
      "Saving checkpoint\n",
      "Training 77 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:03<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3480   31]\n",
      " [ 556  823]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3218   45]\n",
      " [ 818  809]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 88.00%, local accuracy: 82.35%, CohenKappa: 0.55%, AUC: 0.87%, MCC: 0.60%\n",
      "Saving checkpoint\n",
      "Training 78 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:06<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:25<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3810   47]\n",
      " [ 226  807]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3818  111]\n",
      " [ 218  743]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.42%, local accuracy: 93.27%, CohenKappa: 0.78%, AUC: 0.91%, MCC: 0.78%\n",
      "Saving checkpoint\n",
      "Training 79 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:53<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3811   41]\n",
      " [ 225  813]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3821   87]\n",
      " [ 215  767]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 94.56%, local accuracy: 93.82%, CohenKappa: 0.80%, AUC: 0.92%, MCC: 0.80%\n",
      "Saving checkpoint\n",
      "Training 80 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:31<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3973  110]\n",
      " [  63  744]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3961  142]\n",
      " [  75  712]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.46%, local accuracy: 95.56%, CohenKappa: 0.84%, AUC: 0.91%, MCC: 0.84%\n",
      "Saving checkpoint\n",
      "Training 81 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:33<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3991   75]\n",
      " [  45  779]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3963  141]\n",
      " [  73  713]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 97.55%, local accuracy: 95.62%, CohenKappa: 0.84%, AUC: 0.91%, MCC: 0.84%\n",
      "Saving checkpoint\n",
      "Training 82 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:37<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3991   80]\n",
      " [  45  774]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3929  121]\n",
      " [ 107  733]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 97.44%, local accuracy: 95.34%, CohenKappa: 0.84%, AUC: 0.92%, MCC: 0.84%\n",
      "Saving checkpoint\n",
      "Training 83 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:31<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3939   73]\n",
      " [  97  781]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3905  127]\n",
      " [ 131  727]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.52%, local accuracy: 94.72%, CohenKappa: 0.82%, AUC: 0.91%, MCC: 0.82%\n",
      "Saving checkpoint\n",
      "Training 84 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:33<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3987   80]\n",
      " [  49  774]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3869   92]\n",
      " [ 167  762]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 97.36%, local accuracy: 94.70%, CohenKappa: 0.82%, AUC: 0.93%, MCC: 0.82%\n",
      "Saving checkpoint\n",
      "Training 85 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:36<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3760   51]\n",
      " [ 276  803]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3717  106]\n",
      " [ 319  748]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 93.31%, local accuracy: 91.31%, CohenKappa: 0.73%, AUC: 0.90%, MCC: 0.73%\n",
      "Saving checkpoint\n",
      "Training 86 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:35<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:22<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4005  119]\n",
      " [  31  735]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3901  121]\n",
      " [ 135  733]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.93%, local accuracy: 94.76%, CohenKappa: 0.82%, AUC: 0.91%, MCC: 0.82%\n",
      "Saving checkpoint\n",
      "Training 87 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:31<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3949   41]\n",
      " [  87  813]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3810   62]\n",
      " [ 226  792]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 97.38%, local accuracy: 94.11%, CohenKappa: 0.81%, AUC: 0.94%, MCC: 0.81%\n",
      "Saving checkpoint\n",
      "Training 88 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:34<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:24<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3973  120]\n",
      " [  63  734]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3960  146]\n",
      " [  76  708]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 96.26%, local accuracy: 95.46%, CohenKappa: 0.84%, AUC: 0.91%, MCC: 0.84%\n",
      "Saving checkpoint\n",
      "Training 89 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:31<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:22<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3971   34]\n",
      " [  65  820]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3914   66]\n",
      " [ 122  788]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 97.98%, local accuracy: 96.16%, CohenKappa: 0.87%, AUC: 0.95%, MCC: 0.87%\n",
      "Saving checkpoint\n",
      "Training 90 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:26<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:22<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3995   31]\n",
      " [  41  823]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3952   71]\n",
      " [  84  783]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 98.53%, local accuracy: 96.83%, CohenKappa: 0.89%, AUC: 0.95%, MCC: 0.89%\n",
      "Saving checkpoint\n",
      "Training 91 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:25<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:22<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4008   26]\n",
      " [  28  828]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3954   55]\n",
      " [  82  799]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 98.90%, local accuracy: 97.20%, CohenKappa: 0.90%, AUC: 0.96%, MCC: 0.90%\n",
      "Saving checkpoint\n",
      "Training 92 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:25<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:22<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[3978   23]\n",
      " [  58  831]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3948   57]\n",
      " [  88  797]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 98.34%, local accuracy: 97.03%, CohenKappa: 0.90%, AUC: 0.96%, MCC: 0.90%\n",
      "Saving checkpoint\n",
      "Training 93 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:27<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4006   23]\n",
      " [  30  831]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3959   72]\n",
      " [  77  782]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 98.92%, local accuracy: 96.95%, CohenKappa: 0.89%, AUC: 0.95%, MCC: 0.89%\n",
      "Saving checkpoint\n",
      "Training 94 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:38<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4013   36]\n",
      " [  23  818]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3976   66]\n",
      " [  60  788]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 98.79%, local accuracy: 97.42%, CohenKappa: 0.91%, AUC: 0.95%, MCC: 0.91%\n",
      "Saving checkpoint\n",
      "Training 95 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:47<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:22<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4007   22]\n",
      " [  29  832]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3981   49]\n",
      " [  55  805]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 98.96%, local accuracy: 97.87%, CohenKappa: 0.93%, AUC: 0.96%, MCC: 0.93%\n",
      "Saving checkpoint\n",
      "Training 96 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:50<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4018   25]\n",
      " [  18  829]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3975   52]\n",
      " [  61  802]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 99.12%, local accuracy: 97.69%, CohenKappa: 0.92%, AUC: 0.96%, MCC: 0.92%\n",
      "Saving checkpoint\n",
      "Training 97 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:02<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4005   20]\n",
      " [  31  834]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3970   47]\n",
      " [  66  807]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 98.96%, local accuracy: 97.69%, CohenKappa: 0.92%, AUC: 0.96%, MCC: 0.92%\n",
      "Saving checkpoint\n",
      "Training 98 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [46:58<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4016   24]\n",
      " [  20  830]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3978   45]\n",
      " [  58  809]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 99.10%, local accuracy: 97.89%, CohenKappa: 0.93%, AUC: 0.97%, MCC: 0.93%\n",
      "Saving checkpoint\n",
      "Training 99 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:02<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4000    8]\n",
      " [  36  846]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3935   34]\n",
      " [ 101  820]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 99.10%, local accuracy: 97.24%, CohenKappa: 0.91%, AUC: 0.97%, MCC: 0.91%\n",
      "Saving checkpoint\n",
      "Training 100 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7742/7742 [47:04<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 978/978 [01:23<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "Row\n",
      "Confusion Matrix [[4023   29]\n",
      " [  13  825]]\n",
      "*****************************\n",
      "*****************************\n",
      "Local\n",
      "Confusion Matrix [[3982   47]\n",
      " [  54  807]]\n",
      "*****************************\n",
      "Test set: raw accuracy: 99.14%, local accuracy: 97.93%, CohenKappa: 0.93%, AUC: 0.97%, MCC: 0.93%\n",
      "Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import shutil\n",
    "import time\n",
    "from config import num_classes, model_name, model_path, lr_milestones, lr_decay_rate, input_size, \\\n",
    "    root, end_epoch, save_interval, init_lr, batch_size, CUDA_VISIBLE_DEVICES, weight_decay, \\\n",
    "    proposalN, set, channels\n",
    "# from utils.train_model import train\n",
    "from utils.read_dataset import read_dataset\n",
    "from utils.auto_laod_resume import auto_load_resume\n",
    "# from networks.model import MainNet\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def main():\n",
    "    batch_size = 5\n",
    "    end_epoch = 100\n",
    "    input_size = 448\n",
    "#     set='MURA'\n",
    "#     root = './datasets/MURA_DATA'\n",
    "    model_name='fm1fm2attention1'\n",
    "    num_epochs=30\n",
    "    trainloader, testloader = read_dataset(input_size, batch_size, root, set)\n",
    "#     batch = next(iter(trainloader))\n",
    "    \n",
    "    model = MainNet(proposalN=proposalN, num_classes=num_classes, channels=2048, theta=(0.6), red_p=0.15)\n",
    "\n",
    "\n",
    "    criterion = FocalLoss()\n",
    "\n",
    "    parameters = model.parameters()\n",
    "\n",
    "   \n",
    "    save_path = os.path.join(model_path, model_name)\n",
    "    if os.path.exists(save_path):\n",
    "        start_epoch, lr = auto_load_resume(model, save_path, status='train')\n",
    "        assert start_epoch < end_epoch\n",
    "    else:\n",
    "        os.makedirs(save_path)\n",
    "        start_epoch = 0\n",
    "        lr = init_lr\n",
    "\n",
    "    # define optimizers\n",
    "    optimizer = torch.optim.SGD(parameters, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "    scheduler = MultiStepLR(optimizer, milestones=lr_milestones, gamma=lr_decay_rate)\n",
    "#     make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"MainModel_torchviz\", format=\"png\")\n",
    "\n",
    "    time_str = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    shutil.copy('./config.py', os.path.join(save_path, \"{}config.py\".format(time_str)))\n",
    "\n",
    "    train(model=model,\n",
    "          trainloader=trainloader,\n",
    "          testloader=testloader,\n",
    "          criterion=criterion,\n",
    "          optimizer=optimizer,\n",
    "          scheduler=scheduler,\n",
    "          save_path=save_path,\n",
    "          start_epoch=start_epoch,\n",
    "          end_epoch=end_epoch,\n",
    "          num_epochs=30,\n",
    "          save_interval=save_interval)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1a0dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(model_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b02bfbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import shutil\n",
    "import time\n",
    "from config import num_classes, model_name, model_path, lr_milestones, lr_decay_rate, input_size, \\\n",
    "    root, end_epoch, save_interval, init_lr, batch_size, CUDA_VISIBLE_DEVICES, weight_decay, \\\n",
    "    proposalN, set, channels\n",
    "# from utils.train_model import train\n",
    "from utils.read_dataset import read_dataset\n",
    "from utils.auto_laod_resume import auto_load_resume\n",
    "# from networks.model import MainNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1836b8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4237604051.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [63]\u001b[1;36m\u001b[0m\n\u001b[1;33m    CM + = confusion_matrix(labels.cpu(), preds.cpu(),labels=[0,1])\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "def test_model(model, dataloaders, device):\n",
    "    CM=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['test']:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images) #file_name\n",
    "            preds = torch.argmax(outputs.data, 1)\n",
    "            CM + = confusion_matrix(labels.cpu(), preds.cpu(),labels=[0,1])\n",
    "            \n",
    "        tn=CM[0][0]\n",
    "        tp=CM[1][1]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        acc=np.sum(np.diag(CM)/np.sum(CM))\n",
    "        sensitivity=tp/(tp+fn)\n",
    "        precision=tp/(tp+fp)\n",
    "        \n",
    "        print('\\nTestset Accuracy(mean): %f %%' % (100 * acc))\n",
    "        print()\n",
    "        print('Confusion Matirx : ')\n",
    "        print(CM)\n",
    "        print('- Sensitivity : ',(tp/(tp+fn))*100)\n",
    "        print('- Specificity : ',(tn/(tn+fp))*100)\n",
    "        print('- Precision: ',(tp/(tp+fp))*100)\n",
    "        print('- NPV: ',(tn/(tn+fn))*100)\n",
    "        print('- F1 : ',((2*sensitivity*precision)/(sensitivity+precision))*100)\n",
    "        print()\n",
    "                \n",
    "    return acc, CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MainNet(proposalN=proposalN, num_classes=num_classes, channels=2048, theta=(0.6), red_p=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63db0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='one'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62870fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = read_dataset(input_size, batch_size, root, set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529bd801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc0794",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(model_path, model_name)\n",
    "if os.path.exists(save_path):\n",
    "    start_epoch, lr = auto_load_resume(model, save_path, status='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faafde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {['train', 'test'][x]: [len(trainloader.dataset),len(testloader.dataset)][x] for x in range(len(['train', 'val']))}\n",
    "dataloaders = {['train', 'test'][x]: [trainloader,testloader][x] for x in range(len(['train', 'val']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac39b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1af1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from config import input_size, root, proposalN, channels\n",
    "from utils.read_dataset import read_dataset\n",
    "from utils.auto_laod_resume import auto_load_resume\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "\n",
    "#load dataset\n",
    "_, testloader = read_dataset(input_size, batch_size, root, set)\n",
    "\n",
    "\n",
    "model = MainNet(proposalN=proposalN, num_classes=num_classes, channels=2048, theta=(0.6), red_p=0.15)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    epoch = auto_load_resume(model, save_path, status='train')\n",
    "else:\n",
    "    sys.exit('There is not a pth exist.')\n",
    "\n",
    "print('Testing')\n",
    "raw_correct = 0\n",
    "object_correct = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(testloader)):\n",
    "        if set == 'CUB':\n",
    "            x, y, boxes, _ = data\n",
    "        else:\n",
    "            x, y = data\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        local_logits, local_imgs = model(x, epoch, i, 'train', DEVICE)[-3:-1]\n",
    "        # local\n",
    "        pred = local_logits.max(1, keepdim=True)[1]\n",
    "        object_correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "    print('\\nObject branch accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            object_correct, len(testloader.dataset), 100. * object_correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a22bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd04479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a296d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381cc37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a254e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c124b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
